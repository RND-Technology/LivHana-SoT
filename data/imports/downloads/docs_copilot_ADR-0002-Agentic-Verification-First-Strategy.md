# ADR-0002: Adopt Agentic Verification-First Strategy for Tier‑1 Build & Deploy

Status: Proposed  
Date: 2025-09-28  
Context Version: v1.0 (derived from chat synthesis)  
Supersedes: None  
Related: ADR-0001 (memory setup, if present), Complete Technical Implementation ADR

## Context
Early Liv Hana Tier‑1 maturity requires:
- Reliable, minimal, safe diffs
- Deterministic build/test/deploy
- Shift-left security & test discipline
- Explicit role/knowledge modeling to reduce tribal knowledge

An external “agents” role library (pattern of specialized Markdown role definitions) inspired adopting a structured agentic pattern taxonomy to guide AI-assisted development. We must ensure AI outputs are verifiable, not blindly trusted.

## Decision
Adopt a verification-first framework:
1. Every non-trivial AI-generated change must emit a structured verification artifact (plan, tests, risk score, security & rollback considerations).
2. Enforce a canonical set of 20 Agentic Design Patterns (see catalog) for decomposition, reflection, tool choice, risk & policy compliance.
3. Treat agent outputs as proposals—must pass independent static and contextual checks before merge/deploy.
4. Embed provenance markers (e.g., `# generated-by-ai: <pattern>`) removable at merge.
5. Prefer minimal diffs + explicit uncertainty disclosure over speculative abstraction.
6. Maintain all instruction and governance assets under `docs/copilot/` as single source of truth.

## Rationale
- Reduces rework generated by over-scoped AI suggestions.
- Improves auditability (who/what rationale).
- Creates reproducible, enforceable gate inputs.
- Enables incremental gating evolution (advisory → warning → blocking).

## Constraints & Forces
| Force | Pressure | Response |
|-------|----------|----------|
| Time-to-merge | Desire for speed | Keep JSON verification schema terse |
| Security & 21+ Guardrails | High compliance need | Mandatory security checklist pass |
| Cognitive Load | Risk of instruction sprawl | Centralize catalog + mapping tables |
| False Confidence in AI | High risk early | Chain-of-Verification pattern required |

## Alternatives Considered
- Free-form AI suggestions (Rejected): Non-deterministic, hard to gate.
- Human-only review (Rejected): Slow, inconsistent coverage breadth.
- Tool-per-check fragmentation (Rejected): Context fragmentation overhead.

## Consequences
Positive:
- Predictable onboarding of new gates
- Faster risk triage
- Supports future automation (metrics, continuous improvement)

Negative:
- Added upfront friction producing structured artifacts
- Requires cultural adoption & lint/pipeline integration

## Metrics (Success Criteria)
- Reduction in PR rework cycles (target: -30% after 30 days)
- % of AI-assisted diffs with complete verification JSON (target: 95%+)
- Mean time to identify security or test gaps pre-merge
- Number of post-deploy rollbacks attributable to missed verification (target: near-zero)

## Open Questions
- Final numbering alignment with existing ADR scheme (dual numbering observed).
- Whether to auto-generate pattern usage telemetry.
- Formal risk scoring rubric calibration (initial heuristics only).

## Implementation Notes
See: `patterns-catalog-v1.md`, `pipeline-gate-mapping.md`, `runbook-pr-verification-checklist.md`.
<!-- Last verified: 2025-10-02 -->
